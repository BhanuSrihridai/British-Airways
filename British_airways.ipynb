{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhanuSrihridai/British-Airways/blob/Development/British_airways.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jLkusVaNZCIh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNqUT4jkZCIj",
        "outputId": "04225a5d-e63e-4619-deb4-caee913ceaea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping page 1\n",
            "   ---> 100 total reviews\n",
            "Scraping page 2\n",
            "   ---> 200 total reviews\n",
            "Scraping page 3\n",
            "   ---> 300 total reviews\n",
            "Scraping page 4\n",
            "   ---> 400 total reviews\n",
            "Scraping page 5\n",
            "   ---> 500 total reviews\n",
            "Scraping page 6\n",
            "   ---> 600 total reviews\n",
            "Scraping page 7\n",
            "   ---> 700 total reviews\n",
            "Scraping page 8\n",
            "   ---> 800 total reviews\n",
            "Scraping page 9\n",
            "   ---> 900 total reviews\n",
            "Scraping page 10\n",
            "   ---> 1000 total reviews\n"
          ]
        }
      ],
      "source": [
        "base_url=\"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
        "pages=10\n",
        "page_size=100\n",
        "\n",
        "reviews=[]\n",
        "\n",
        "for i in range(1,pages+1):\n",
        "\n",
        "    print(f\"Scraping page {i}\")\n",
        "\n",
        "    # Creating url from a page to collect data\n",
        "    # url = https://www.airlinequality.com/airline-reviews/british-airways/page/2/?sortby=post_date%3ADesc&pagesize=100\n",
        "\n",
        "    url=f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
        "\n",
        "    # Collect data from this page\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse content\n",
        "    content = response.content\n",
        "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
        "        reviews.append(para.get_text())\n",
        "\n",
        "    print(f\"   ---> {len(reviews)} total reviews\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liGqfGveZCIk",
        "outputId": "376fd747-5902-4232-d0fb-eedea0af05cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>✅ Trip Verified |  Busy day at LHR and flight ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>✅ Trip Verified |  Faro to Heathrow. Flight wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>✅ Trip Verified |  British Airways are in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>✅ Trip Verified |  Warsaw to London. Everythin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>✅ Trip Verified |  Belfast City to Atlanta via...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>✅ Trip Verified |   The worst airline I have e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>✅ Trip Verified |   I am a frequent flyer with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>✅ Trip Verified |  Absolutely bad experience w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>✅ Trip Verified |  A short hop from London to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Not Verified | Horrible airline. Does not care...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               reviews\n",
              "140  ✅ Trip Verified |  Busy day at LHR and flight ...\n",
              "887  ✅ Trip Verified |  Faro to Heathrow. Flight wa...\n",
              "419  ✅ Trip Verified |  British Airways are in the ...\n",
              "632  ✅ Trip Verified |  Warsaw to London. Everythin...\n",
              "856  ✅ Trip Verified |  Belfast City to Atlanta via...\n",
              "26   ✅ Trip Verified |   The worst airline I have e...\n",
              "19   ✅ Trip Verified |   I am a frequent flyer with...\n",
              "421  ✅ Trip Verified |  Absolutely bad experience w...\n",
              "567  ✅ Trip Verified |  A short hop from London to ...\n",
              "96   Not Verified | Horrible airline. Does not care..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"reviews\"] = reviews\n",
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEyOMS2IZCIk"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"C:\\Data Science\\Internship\\British Airways\\British Airways.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"British Airways.csv\")"
      ],
      "metadata": {
        "id": "j3JtTeMe65OY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuikA9otZCIk"
      },
      "source": [
        "Removing the punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ek1oss63ZCIl",
        "outputId": "90a67514-8dda-4ef2-e499-2ec562febf91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-91d5aada4604>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['review_processed'] = df['reviews'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n"
          ]
        }
      ],
      "source": [
        "df['review_processed'] = df['reviews'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YjsI93YcZCIm",
        "outputId": "b20592d3-f522-4d5e-ba2b-65c3ca444a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Trip Verified    Booked online months ago an...\n",
              "1        Trip Verified    The flight was on time  The...\n",
              "2      Not Verified    Angry  disappointed  and unsat...\n",
              "3        Trip Verified    As an infrequent flyer  Bri...\n",
              "4      Not Verified    A totally unremarkable flight ...\n",
              "                             ...                        \n",
              "995      Trip Verified    San Francisco to London  Te...\n",
              "996      Trip Verified    Heathrow to Vancouver  The ...\n",
              "997      Trip Verified    London to Bucharest  First ...\n",
              "998      Trip Verified    I forgot I had purchased a ...\n",
              "999      Trip Verified    When the passenger in front...\n",
              "Name: review_processed, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df[\"review_processed\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IlU6eGZZCIm"
      },
      "source": [
        "Replacing the shorter words with space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "twyc_cJkZCIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64636a03-ecff-4c9b-fb8b-257eea9f6b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Trip Verified Booked online months ago and the...\n",
              "1      Trip Verified The flight was time The crew wer...\n",
              "2      Not Verified Angry disappointed and unsatisfie...\n",
              "3      Trip Verified infrequent flyer British Airways...\n",
              "4      Not Verified totally unremarkable flight time ...\n",
              "                             ...                        \n",
              "995    Trip Verified San Francisco London Terrible se...\n",
              "996    Trip Verified Heathrow Vancouver The seats boo...\n",
              "997    Trip Verified London Bucharest First class gro...\n",
              "998    Trip Verified forgot had purchased hand baggag...\n",
              "999    Trip Verified When the passenger front recline...\n",
              "Name: review_processed, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df['review_processed']=df['review_processed'].apply(lambda row: ' '.join([word for word in row.split() if len(word)>2]))\n",
        "df['review_processed']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnzS8Y59ZCIn"
      },
      "source": [
        "Converting all words into lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h0xJDPAWZCIn",
        "outputId": "8549eefa-9df7-4fa2-80c7-174d88837c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      trip verified booked online months ago and the...\n",
              "1      trip verified the flight was time the crew wer...\n",
              "2      not verified angry disappointed and unsatisfie...\n",
              "3      trip verified infrequent flyer british airways...\n",
              "4      not verified totally unremarkable flight time ...\n",
              "                             ...                        \n",
              "995    trip verified san francisco london terrible se...\n",
              "996    trip verified heathrow vancouver the seats boo...\n",
              "997    trip verified london bucharest first class gro...\n",
              "998    trip verified forgot had purchased hand baggag...\n",
              "999    trip verified when the passenger front recline...\n",
              "Name: review_processed, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df['review_processed']=[row.lower() for row in df['review_processed']]\n",
        "df['review_processed']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS8ePrVAZCIp"
      },
      "source": [
        "Removing the stop words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ],
      "metadata": {
        "id": "n4d1eYCKZEE8",
        "outputId": "5cca71d7-33eb-4ae6-ac09-7331faf2e54c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "stop_words = stopwords.words('english') # extracting all the stop words in english language and storing it in a variable called stop_words -> set\n",
        "\n",
        "# Making custom list of words to be removed\n",
        "add_words = ['movie','film','one','make','even','see','movies','get','makes','making','time','watch','character', 'like', 'good','well','would','really']\n",
        "\n",
        "# Adding to the list of words\n",
        "stop_words.extend(add_words)\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stopwords(rev):\n",
        "    # iNPUT : IT WILL TAKE ROW/REVIEW AS AN INPUT\n",
        "    # take the paragraph, break into words, check if the word is a stop word, remove if stop word, combine the words into a para again\n",
        "    review_tokenized = word_tokenize(rev)\n",
        "    rev_new = \" \".join([i for i in review_tokenized  if i not in stop_words])\n",
        "    return rev_new\n",
        "\n",
        "# Removing stopwords\n",
        "df['review_processed'] = [remove_stopwords(r) for r in df['review_processed']]"
      ],
      "metadata": {
        "id": "XMp7iaG95dwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(rev):\n",
        "    # input : IT WILL TAKE ROW/REVIEW AS AN INPUT\n",
        "    # take the paragraph, break into words, check if the word is a stop word, remove if stop word, combine the words into a para again\n",
        "    review_tokenized = word_tokenize(rev)\n",
        "    rev_new = \" \".join([i for i in review_tokenized  if i not in stop_words])\n",
        "    return rev_new"
      ],
      "metadata": {
        "id": "vcVuzBPb-dXv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review_processed']=[remove_stopwords(r) for r in df['review_processed']]"
      ],
      "metadata": {
        "id": "LrP-6c-n-ryc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review_processed']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFLndeJA_CPt",
        "outputId": "526e2ac9-a1a3-4d88-f840-a8953c28323c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      trip verified booked online months ago hitch r...\n",
              "1      trip verified flight time crew polite story ou...\n",
              "2      verified angry disappointed unsatisfied route ...\n",
              "3      trip verified infrequent flyer british airways...\n",
              "4      verified totally unremarkable flight time comf...\n",
              "                             ...                        \n",
              "995    trip verified san francisco london terrible se...\n",
              "996    trip verified heathrow vancouver seats booked ...\n",
              "997    trip verified london bucharest first class gro...\n",
              "998    trip verified forgot purchased hand baggage fa...\n",
              "999    trip verified passenger front reclines seat ma...\n",
              "Name: review_processed, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}